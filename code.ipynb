{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ce7bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88a779e2",
   "metadata": {},
   "outputs": [],
   "source": [
    ,
    "def load_datasets():\n",
    "    train_url = input(\"Enter the train data URL (or path): \").strip()\n",
    "    test_url = input(\"Enter the test data URL (or path): \").strip()\n",
    "\n",
    "    try:\n",
    "        df_train = pd.read_csv(train_url)\n",
    "        df_test = pd.read_csv(test_url)\n",
    "\n",
    "        print(\"\\n Successfully loaded datasets.\")\n",
    "        print(f\"\\n Training Dataset:\\n{df_train.head()}\")\n",
    "        print(f\"\\n Testing Dataset:\\n{df_test.head()}\")\n",
    "\n",
    "        return df_train, df_test\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n Error loading datasets: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63505b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data\n",
    "def preprocess_data(df, is_train=True, reference_columns=None):\n",
    "    print(\"\\n🔧 Preprocessing Data...\")\n",
    "    df = df.copy()\n",
    "\n",
    
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
    "\n",
    "    # Drop target column if exists\n",
    "    if is_train:\n",
    "        df = df.drop(columns=['status'], errors='ignore')\n",
    "\n",
    "    # Handle missing features in test data\n",
    "    if not is_train and reference_columns is not None:\n",
    "        for feature in reference_columns:\n",
    "            if feature not in df.columns:\n",
    "                df[feature] = 0  # Add missing features with default value\n",
    "        df = df[reference_columns]  # Align column order to match the training data\n",
    "\n",
    "    # Fill missing values\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "    # Standard scaling\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "    return pd.DataFrame(df_scaled, columns=df.columns), scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "676eac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Isolation Forest\n",
    "def isolation_forest_model(X):\n",
    "    print(\"\\n🔧 Training Isolation Forest...\")\n",
    "    model = IsolationForest(random_state=42, contamination=0.1)\n",
    "    model.fit(X)\n",
    "    return model\n",
    "\n",
    "#  Train One-Class SVM\n",
    "def one_class_svm_model(X):\n",
    "    print(\"\\n🔧 Training One-Class SVM...\")\n",
    "    model = OneClassSVM(kernel='rbf', gamma='auto', nu=0.05)\n",
    "    model.fit(X)\n",
    "    return model\n",
    "\n",
    "# Train AutoEncoder\n",
    "def autoencoder_model(X):\n",
    "    print(\"\\n🔧 Training AutoEncoder...\")\n",
    "    input_dim = X.shape[1]\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(input_dim, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(X, X, epochs=10, batch_size=32, verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aef5b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Anomalies\n",
    "def predict_anomalies(X_test, iso_model, svm_model, auto_model, df_test):\n",
    "    print(\"\\n🔍 Predicting anomalies in test data...\")\n",
    "\n",
    "    # Isolation Forest\n",
    "    iso_preds = iso_model.predict(X_test)  \n",
    "    iso_anomalies = np.where(iso_preds == -1)[0]\n",
    "\n",
    "    # One-Class SVM\n",
    "    svm_preds = svm_model.predict(X_test)  \n",
    "    svm_anomalies = np.where(svm_preds == -1)[0]\n",
    "\n",
    "    # AutoEncoder\n",
    "    reconstructions = auto_model.predict(X_test)\n",
    "    mse = np.mean(np.power(X_test - reconstructions, 2), axis=1)\n",
    "    threshold = np.percentile(mse, 95)  # Set threshold at 95th percentile\n",
    "    auto_anomalies = np.where(mse > threshold)[0]\n",
    "\n",
    "    print(f\"\\n Results:\")\n",
    "    print(f\"Isolation Forest detected {len(iso_anomalies)} anomalies.\")\n",
    "    print(f\"One-Class SVM detected {len(svm_anomalies)} anomalies.\")\n",
    "    print(f\"AutoEncoder detected {len(auto_anomalies)} anomalies.\")\n",
    "\n",
    "    # Extract and display anomaly rows\n",
    "    anomalies = {\n",
    "        \"IsolationForest\": df_test.iloc[iso_anomalies],\n",
    "        \"OneClassSVM\": df_test.iloc[svm_anomalies],\n",
    "        \"AutoEncoder\": df_test.iloc[auto_anomalies],\n",
    "    }\n",
    "\n",
    "    for model, rows in anomalies.items():\n",
    "        print(f\"\\n🛑 Anomalies identified by {model}:\")\n",
    "        print(rows)\n",
    "\n",
    "    return anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de9abd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Successfully loaded datasets.\n",
      "\n",
      " Training Dataset:\n",
      "   duration_sec protocol  bytes_sent  bytes_received error_flag  fragmented  \\\n",
      "0     22.472407      dns        6717            9437        ACK           0   \n",
      "1     57.042858     http        2579            6919        RST           0   \n",
      "2     43.919637      ftp        6584            3819        FIN           0   \n",
      "3     35.919509      ftp        9927            2845        FIN           1   \n",
      "4      9.361118      dns        7521            7583        RST           1   \n",
      "\n",
      "   priority  active_connections  idle_time_sec   status  \n",
      "0         2                 302     171.395683   normal  \n",
      "1         2                 180     198.633603   normal  \n",
      "2         4                 433     163.133672  anomaly  \n",
      "3         0                 483     259.347864   normal  \n",
      "4         4                 192     220.172976   normal  \n",
      "\n",
      " Testing Dataset:\n",
      "   duration_sec protocol  bytes_sent  bytes_received error_flag  fragmented  \\\n",
      "0     17.716697     http         730            2449        ACK           1   \n",
      "1     47.604435      ftp        8953            5799        RST           1   \n",
      "2     11.113707      dns        2952            1341        RST           1   \n",
      "3     55.065149     http        1087            1225        FIN           0   \n",
      "4     25.471646      ftp        7722            9482        RST           0   \n",
      "\n",
      "   priority  active_connections  idle_time_sec  \n",
      "0         3                 151     180.178300  \n",
      "1         3                 301     154.703828  \n",
      "2         2                 490     275.817592  \n",
      "3         4                 160     149.089045  \n",
      "4         3                 123     297.647404  \n",
      "\n",
      "🔧 Preprocessing Data...\n",
      "\n",
      "🔧 Preprocessing Data...\n",
      "\n",
      "🔧 Training Isolation Forest...\n",
      "\n",
      "🔧 Training One-Class SVM...\n",
      "\n",
      "🔧 Training AutoEncoder...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skdha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.9821\n",
      "Epoch 2/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9100 \n",
      "Epoch 3/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8146 \n",
      "Epoch 4/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.7005 \n",
      "Epoch 5/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5531 \n",
      "Epoch 6/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4185 \n",
      "Epoch 7/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3096 \n",
      "Epoch 8/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2248 \n",
      "Epoch 9/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1476 \n",
      "Epoch 10/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0848 \n",
      "\n",
      "🔍 Predicting anomalies in test data...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\n",
      " Results:\n",
      "Isolation Forest detected 3 anomalies.\n",
      "One-Class SVM detected 5 anomalies.\n",
      "AutoEncoder detected 1 anomalies.\n",
      "\n",
      "🛑 Anomalies identified by IsolationForest:\n",
      "    duration_sec protocol  bytes_sent  bytes_received error_flag  fragmented  \\\n",
      "4      25.471646      ftp        7722            9482        RST           0   \n",
      "6      48.944919      dns        9838            5201        RST           0   \n",
      "10      0.155041      dns        6752            5289        RST           1   \n",
      "\n",
      "    priority  active_connections  idle_time_sec  \n",
      "4          3                 123     297.647404  \n",
      "6          4                  75      62.553154  \n",
      "10         0                 484     114.186988  \n",
      "\n",
      "🛑 Anomalies identified by OneClassSVM:\n",
      "    duration_sec protocol  bytes_sent  bytes_received error_flag  fragmented  \\\n",
      "4      25.471646      ftp        7722            9482        RST           0   \n",
      "5       5.222338      dns        7427            6864        ACK           0   \n",
      "6      48.944919      dns        9838            5201        RST           0   \n",
      "10      0.155041      dns        6752            5289        RST           1   \n",
      "14     47.624631      ftp         869            6804        ACK           0   \n",
      "\n",
      "    priority  active_connections  idle_time_sec  \n",
      "4          3                 123     297.647404  \n",
      "5          2                 246     255.427487  \n",
      "6          4                  75      62.553154  \n",
      "10         0                 484     114.186988  \n",
      "14         0                 340     237.009131  \n",
      "\n",
      "🛑 Anomalies identified by AutoEncoder:\n",
      "   duration_sec protocol  bytes_sent  bytes_received error_flag  fragmented  \\\n",
      "4     25.471646      ftp        7722            9482        RST           0   \n",
      "\n",
      "   priority  active_connections  idle_time_sec  \n",
      "4         3                 123     297.647404  \n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "#  MAIN FLOW\n",
    "# ============================\n",
    "\n",
    "# Load data\n",
    "df_train, df_test = load_datasets()\n",
    "\n",
    "\n",
    "X_train, train_scaler = preprocess_data(df_train, is_train=True)\n",
    "reference_columns = X_train.columns.tolist()\n",
    "\n",
    "\n",
    "X_test, _ = preprocess_data(df_test, is_train=False, reference_columns=reference_columns)\n",
    "\n",
    "# Train models\n",
    "iso_model = isolation_forest_model(X_train)\n",
    "svm_model = one_class_svm_model(X_train)\n",
    "auto_model = autoencoder_model(X_train)\n",
    "\n",
    "# Predict and display anomaly rows\n",
    "anomalies = predict_anomalies(X_test, iso_model, svm_model, auto_model, df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
